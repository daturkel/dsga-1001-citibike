{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "import pickle\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO, StringIO\n",
    "from csv import reader\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2013, 2020)\n",
    "months = range(1, 13)\n",
    "year_months = [str(y) + str(m).zfill(2) for y in years for m in months]\n",
    "# exclude months before citibike started and in the future\n",
    "year_months = year_months[5:-4]\n",
    "url_start = \"https://s3.amazonaws.com/tripdata/\"\n",
    "url_end = \"-citibike-tripdata.zip\"\n",
    "url_end_alt = \"-citibike-tripdata.csv.zip\"\n",
    "good_columns = [\n",
    "    \"tripduration\",\n",
    "    \"starttime\",\n",
    "    \"startstationid\",\n",
    "    \"endstationid\",\n",
    "    \"usertype\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting csv 75 of 75, 201908\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# this will download all csvs\n",
    "for i, ym in enumerate(year_months):\n",
    "    if not os.path.isfile(f\"{ym}.csv.gz\"):\n",
    "        clear_output()\n",
    "        print(f\"getting csv {i+1} of {len(year_months)}, {ym}\")\n",
    "        # there are two different url formats, so we try the first one\n",
    "        # and fall back to the second if the first returns a 404\n",
    "        try:\n",
    "            response = requests.get(url_start + ym + url_end)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.HTTPError:\n",
    "            response = requests.get(url_start + ym + url_end_alt)\n",
    "        zf = ZipFile(BytesIO(response.content))\n",
    "        csv = zf.read(zf.namelist()[0]).decode()\n",
    "        df = pd.read_csv(\n",
    "            StringIO(csv),\n",
    "            # the column names change somewhat over the months, so we use\n",
    "            # this lambda to reduce them to a normalized format\n",
    "            usecols=lambda x: x.lower().replace(\" \", \"\") in good_columns,\n",
    "            # use column indices instead of names since the names change slightly\n",
    "            dtype={3: \"Int64\", 4: \"Int64\", 12: \"category\"},\n",
    "        )\n",
    "        # normalize once and for all\n",
    "        df.columns = [col.lower().replace(\" \", \"\") for col in df.columns]\n",
    "        # save some space by replacing Subscriber with S and Customer with C\n",
    "        df.iloc[:, -1].cat.rename_categories(lambda x: x[0], inplace=True)\n",
    "        df.to_csv(f\"{ym}.csv.gz\", index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxLedger:\n",
    "    def __init__(self):\n",
    "        self.max = defaultdict(lambda: datetime.datetime.min)\n",
    "        self.min = defaultdict(lambda: datetime.datetime.max)\n",
    "\n",
    "    def enter_stats(self, station_id, min_start_time, max_start_time):\n",
    "        if min_start_time < self.min[station_id]:\n",
    "            self.min[station_id] = min_start_time\n",
    "        if self.max[station_id] < max_start_time:\n",
    "            self.max[station_id] = max_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201908\n"
     ]
    }
   ],
   "source": [
    "ledger = MinMaxLedger()\n",
    "\n",
    "for ym in year_months:\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            f\"{ym}.csv.gz\",\n",
    "            dtype={\n",
    "                \"tripduration\": \"Int64\",\n",
    "                \"startstationid\": \"Int64\",\n",
    "                \"usertype\": \"category\",\n",
    "            },\n",
    "            parse_dates=[\"starttime\"],\n",
    "            infer_datetime_format=True,\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        break\n",
    "    clear_output()\n",
    "    print(ym)\n",
    "    stats = df.groupby(\"startstationid\").agg(\n",
    "        min_start_time=pd.NamedAgg(\"starttime\", \"min\"),\n",
    "        max_start_time=pd.NamedAgg(\"starttime\", \"max\"),\n",
    "    )\n",
    "    stats.apply(\n",
    "        lambda x: ledger.enter_stats(x.name, x.min_start_time, x.max_start_time), axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ts_stations.pickle\", \"wb\") as f:\n",
    "    pickle.dump([dict(ledger.min), dict(ledger.max)], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
